{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HCP Filtering\n",
    "- Get data from a Cohort created from the Cohort Builder UI\n",
    "- Filter Medical Events table to return only rows with a Modifier\n",
    "- Upload final dataset to MapView\n",
    "- Schedule refresh\n",
    "- Export dataset to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries & Connect to Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the Komodo client\n",
    "from komodo.client import Client\n",
    "from komodo.definitions.models.cohorts.cohort_create import CohortCreate\n",
    "from dotenv import load_dotenv, set_key\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from komodo.snowflake import get_snowflake_connection\n",
    "from snowflake.connector.pandas_tools import pd_writer\n",
    "from datetime import datetime\n",
    "from komodo.dataset import upload_dataset_to_maplab\n",
    "from time import sleep\n",
    " \n",
    "\n",
    "now = datetime.now()\n",
    "load_dotenv()\n",
    "client = Client()\n",
    "\n",
    "\n",
    "### Connect to Snowflake\n",
    "print(\"--- Connecting to Snowflake ---\")\n",
    "\n",
    "account_id = os.getenv(\"KOMODO_ACCOUNT_ID\")\n",
    "\n",
    "conn = get_snowflake_connection(account_id)\n",
    "curs = conn.cursor()\n",
    "curs.execute(\"USE ROLE CUSTOMER_ROLE\")\n",
    "print(\"--- Success connecting to Snowflake ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Cohort Definition & Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_definition_id = \"fltr_def_BMEBEGSBOFPMQLJT\"  # replace this cohort definition ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the JSON payload\n",
    "cohort_payload = {\n",
    "    \"name\": \"Phompholyx Providers Cohort\",\n",
    "    \"definition\": {\n",
    "        \"cohort_definition\": {\n",
    "            \"filters\": [{\n",
    "                \"name\": \"filter_dfn\", \n",
    "                \"filter_definition\": {\"filter_definition_id\": cohort_definition_id},\n",
    "                \"time_filter\": {  # optional\n",
    "                    \"ranges\": [\n",
    "                        [\"2024-01-01\", \"2024-01-31\"]\n",
    "                    ]\n",
    "                }\n",
    "            }],\n",
    "            \"entities\": [\"patient\"],\n",
    "            \"source_filter\": {\n",
    "                \"version\": \"release\", \n",
    "                \"include_rejected_claims\": False\n",
    "            },\n",
    "        },\n",
    "        # The below script will create tables in the MapLab UI as well\n",
    "        \"output_format\": {\n",
    "            \"count_entities\": False,\n",
    "            \"entities_to_count\": [],\n",
    "            \"outputs\": [\n",
    "                {\n",
    "                    \"output_format\": \"snowflake-table\",\n",
    "                    \"output_type\": \"plaid-medical-events\",\n",
    "                },\n",
    "                {\n",
    "                    \"output_format\": \"snowflake-table\",\n",
    "                    \"output_type\": \"plaid-pharmacy-events\",\n",
    "                },\n",
    "                {\n",
    "                    \"output_format\": \"snowflake-table\",\n",
    "                    \"output_type\": \"plaid-patient-demographics\",\n",
    "                },\n",
    "                {\n",
    "                    \"output_format\": \"snowflake-table\",\n",
    "                    \"output_type\": \"plaid-patient-geography\",\n",
    "                },\n",
    "                {\n",
    "                    \"output_format\": \"snowflake-table\",\n",
    "                    \"output_type\": \"plaid-plans\",\n",
    "                },\n",
    "                {\n",
    "                    \"output_format\": \"snowflake-table\",\n",
    "                    \"output_type\": \"plaid-providers\",\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "    },\n",
    "    \"definition_schema_version\": \"1.0.0\",\n",
    "}\n",
    "\n",
    "# create the CohortCreate instance with the JSON payload\n",
    "cohort_create = CohortCreate.from_dict(cohort_payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### All of the available output formats\n",
    "            # \"outputs\": [\n",
    "            #     {\n",
    "            #         \"output_format\": \"snowflake-table\",\n",
    "            #         \"output_type\": \"plaid-medical-events\",\n",
    "            #     },\n",
    "            #     {\n",
    "            #         \"output_format\": \"snowflake-table\",\n",
    "            #         \"output_type\": \"plaid-pharmacy-events\",\n",
    "            #     },\n",
    "            #     {\n",
    "            #         \"output_format\": \"snowflake-table\",\n",
    "            #         \"output_type\": \"plaid-patient-demographics\",\n",
    "            #     },\n",
    "            #     {\n",
    "            #         \"output_format\": \"snowflake-table\",\n",
    "            #         \"output_type\": \"plaid-patient-enrollment\",\n",
    "            #     },\n",
    "            #     {\n",
    "            #         \"output_format\": \"snowflake-table\",\n",
    "            #         \"output_type\": \"plaid-patient-geography\",\n",
    "            #     },\n",
    "            #     {\n",
    "            #         \"output_format\": \"snowflake-table\",\n",
    "            #         \"output_type\": \"plaid-plans\",\n",
    "            #     },\n",
    "            #     {\n",
    "            #         \"output_format\": \"snowflake-table\",\n",
    "            #         \"output_type\": \"plaid-providers\",\n",
    "            #     },\n",
    "            #     {\n",
    "            #         \"output_format\": \"snowflake-table\",\n",
    "            #         \"output_type\": \"plaid-patient-closed\",\n",
    "            #     },\n",
    "            #     {\n",
    "            #         \"output_format\": \"snowflake-table\",\n",
    "            #         \"output_type\": \"plaid-patient-insurance\",\n",
    "            #     },\n",
    "            #     {\n",
    "            #         \"output_format\": \"snowflake-table\",\n",
    "            #         \"output_type\": \"plaid-mortality\",\n",
    "            #     },\n",
    "            #     {\n",
    "            #         \"output_format\": \"snowflake-table\",\n",
    "            #         \"output_type\": \"plaid-patient-race-ethnicity\",\n",
    "            #     },\n",
    "            # ],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the create_cohort operation\n",
    "cohort_create_response = client.definitions.create_cohort(cohort_create)\n",
    "\n",
    "# save the ID of the cohort\n",
    "cohort_id = cohort_create_response.id\n",
    "\n",
    "# print the cohort ID\n",
    "cohort_id\n",
    "\n",
    "# store the cohort ID as an environment variable that can be used across cookbook files\n",
    "set_key('.env', 'cohort_id', cohort_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cohort_id = \"cht_XBWBXEDTIATCKZOK\"  # replace this cohort ID if inputting manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_response = client.definitions.get_cohort(cohort_id)\n",
    " \n",
    "while cohort_response.cohort_run.finished_at is None and cohort_response.cohort_run.error_message is None:\n",
    "    cohort_response = client.definitions.get_cohort(cohort_id)\n",
    "    print(f\"Cohort status is {cohort_response.cohort_run.status.value}\")\n",
    "    if cohort_response.cohort_run.status == \"FINISHED\":\n",
    "        break\n",
    "    sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_snowflake_query(query, conn):\n",
    "    \"\"\"Execute a query against Snowflake and return results as a DataFrame\"\"\"\n",
    "    try:\n",
    "        return pd.read_sql(query, conn)\n",
    "    except Exception as e:\n",
    "        print(f\"Query failed: {e}\")\n",
    "        return None\n",
    "\n",
    "# Dictionary to store all datasets\n",
    "datasets = {}\n",
    "\n",
    "for index, item in enumerate(cohort_response.cohort_run.output.outputs):\n",
    "    # Get dataset information\n",
    "    cohort_output_dataset = item.dataset_id\n",
    "    dataset = client.data_catalog.get_dataset(dataset_id=cohort_output_dataset)\n",
    "    dataset_table = dataset.manifestations[0].fully_qualified_name\n",
    "    \n",
    "    # Extract the table type\n",
    "    table_parts = dataset_table.split('_')\n",
    "    table_type = '_'.join(table_parts[-2:])  # Get the last two parts\n",
    "    \n",
    "    # Create a query to fetch the data\n",
    "    query = f\"SELECT * FROM {dataset_table}\"\n",
    "    \n",
    "    # Execute the query and store the result in a dataframe\n",
    "    try:\n",
    "        df = execute_snowflake_query(query, conn)\n",
    "        \n",
    "        if df is not None:\n",
    "            datasets[table_type] = df\n",
    "            print(f\"Successfully created dataset for {table_type}\")\n",
    "        else:\n",
    "            print(f\"No data returned for {table_type}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating dataset for {table_type}: {e}\")\n",
    "\n",
    "# Print available datasets\n",
    "print(\"\\nAvailable datasets:\")\n",
    "for key in datasets.keys():\n",
    "    print(f\"- {key}: {len(datasets[key])} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store all dataset references and preview DataFrames\n",
    "dataset_refs = {}\n",
    "dataset_previews = {}\n",
    "\n",
    "# First, collect all the dataset references\n",
    "for index, item in enumerate(cohort_response.cohort_run.output.outputs):\n",
    "    cohort_output_dataset = item.dataset_id\n",
    "    dataset = client.data_catalog.get_dataset(dataset_id=cohort_output_dataset)\n",
    "    dataset_table = dataset.manifestations[0].fully_qualified_name\n",
    "    print(f\"Dataset table: {dataset_table}\")\n",
    "    \n",
    "    # Extract the table type\n",
    "    table_parts = dataset_table.split('_')\n",
    "    table_type = '_'.join(table_parts[-2:])\n",
    "    \n",
    "    # Store the reference\n",
    "    dataset_refs[table_type] = dataset_table\n",
    "\n",
    "# Now create preview DataFrames with limited rows\n",
    "for table_type, table_name in dataset_refs.items():\n",
    "    # Create a query that limits the number of rows\n",
    "    preview_query = f\"SELECT * FROM {table_name} LIMIT 100\"  # Adjust the limit as needed\n",
    "    \n",
    "    try:\n",
    "        # Execute the query to get a preview\n",
    "        # Replace conn with your actual snowflake connection\n",
    "        preview_df = pd.read_sql(preview_query, conn)\n",
    "        \n",
    "        # Store the preview DataFrame\n",
    "        dataset_previews[table_type] = preview_df\n",
    "        print(f\"Successfully created preview for {table_type} ({len(preview_df)} rows)\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating preview for {table_type}: {e}\")\n",
    "\n",
    "# Function to display pandas head previews\n",
    "def display_pandas_previews(previews, rows=5):\n",
    "    \"\"\"\n",
    "    Display pandas head() previews for each dataset\n",
    "    \n",
    "    Parameters:\n",
    "    - previews: Dictionary mapping dataset names to pandas DataFrames\n",
    "    - rows: Number of rows to show in preview\n",
    "    \"\"\"\n",
    "    for name, df in previews.items():\n",
    "        print(f\"\\n{'='*80}\\n{name} PREVIEW:\\n{'='*80}\")\n",
    "        print(f\"\\nShape: {df.shape[0]} rows Ã— {df.shape[1]} columns\")\n",
    "        print(f\"Columns: {', '.join(df.columns)}\")\n",
    "        print(f\"\\nFirst {rows} rows:\")\n",
    "        print(df.head(rows))  \n",
    "\n",
    "# Display the previews\n",
    "display_pandas_previews(dataset_previews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = f\"\"\"\n",
    "SELECT * FROM COHORTS.PROD.COHORT_RUN_CHT_JCNGYWQIYLCDPJXT_0_PLAID_MEDICAL_EVENTS\n",
    "    WHERE UPPER(MODIFIERS) IS NOT NULL\n",
    ";\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and fetch results\n",
    "final_dataset = pd.read_sql(sql_query, conn)\n",
    "\n",
    "# Print the results\n",
    "final_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Final Dataset(s) to MapLab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the name of the dataset to be uploaded to the Komodo platform\n",
    "# add the current date and time to the end of the dataset name to make it more distinct\n",
    "final_dataset_datetime = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "final_dataset_dataset_name = \"ABECMA_FINAL_DATASET_FROM_COHORT_RUN_\" + final_dataset_datetime\n",
    "\n",
    "# call the upload_dataset_to_maplab function\n",
    "dataset_upload_dataset = upload_dataset_to_maplab(final_dataset, final_dataset_dataset_name)\n",
    "\n",
    "# save the ID of the dataset\n",
    "dataset_id = dataset_upload_dataset.id\n",
    "\n",
    "# print the dataset ID\n",
    "dataset_id\n",
    "\n",
    "# store the dataset ID as an environment variable that can be used in subsequent cookbook files\n",
    "from dotenv import load_dotenv, set_key\n",
    "\n",
    "set_key(\".env\", \"dataset_id\", dataset_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
